{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GUS Dataset Annotation with Gemini\n",
                "\n",
                "This notebook annotates the `ethical-spectacle/gus-dataset-v1` using the Gemini API to identify Generalizations (GEN), Unfairness (UNFAIR), and Stereotypes (STEREO)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if not already installed\n",
                "!pip install -q google-generativeai datasets tqdm python-dotenv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "from tqdm import tqdm\n",
                "import google.generativeai as genai\n",
                "from datasets import load_dataset\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# --- CONFIGURATION ---\n",
                "# Load API key from .env file\n",
                "load_dotenv()\n",
                "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
                "\n",
                "if not GOOGLE_API_KEY:\n",
                "    raise ValueError(\"Please set GOOGLE_API_KEY in your .env file.\")\n",
                "\n",
                "genai.configure(api_key=GOOGLE_API_KEY)\n",
                "\n",
                "# Model Name: User requested 'gemini 3 flash'. \n",
                "MODEL_NAME = \"gemini-3-flash-preview\"\n",
                "model = genai.GenerativeModel(MODEL_NAME)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- DEFINITIONS & PROMPTS ---\n",
                "\n",
                "SYSTEM_INSTRUCTION = \"\"\"\n",
                "You are an expert annotator for ethical AI datasets. Your task is to annotate text for three specific categories of bias: \n",
                "1. Generalizations (GEN)\n",
                "2. Unfairness (UNFAIR)\n",
                "3. Stereotypes (STEREO)\n",
                "\n",
                "Please analyze the input text and provide annotations in BIO format tags (B-TAG, I-TAG, O) for each word/token in the text. \n",
                "However, to simplify the output for this specific task, please return the result as a JSON object containing the list of tags corresponding to the words in the input sentence.\n",
                "\n",
                "### Definitions\n",
                "\n",
                "**1. GEN (Generalizations)**\n",
                "Tag: B-GEN / I-GEN\n",
                "Description: Any broad generalization of a group or ubiquitous classifiers, including adjectives/descriptors (e.g., 'my whole family', 'all Muslims', 'Women in general', 'everyone in this city', 'all politicians', 'tall people', 'women', 'the rocketry club', 'students', 'tall boys')\n",
                "\n",
                "**2. UNFAIR (Unfairness)**\n",
                "Tag: B-UNFAIR / I-UNFAIR\n",
                "Description: Any harsh or unjust characterization or offensive language. (e.g., 'such an idiot', 'stupid idea', 'totally useless', 'worst team ever', 'bad driver')\n",
                "\n",
                "**3. STEREO (Stereotypes)**\n",
                "Tag: B-STEREO / I-STEREO\n",
                "Description: Any statement (multiple words) that contain a stereotype targeting a group of people, both explicitly and unconsiously. (e.g., 'women are bad drivers', 'Asians are good at math', 'Southerners are dumb', 'teenagers are irresponsible', 'men are gross').\n",
                "\n",
                "### Output Format\n",
                "Return a JSON object with a single key \"annotations\" which is a list of strings representing the BIO tags for the input tokens. \n",
                "Ensure the length of the tag list matches the number of words/tokens in the input.\n",
                "Also include a brief \"rationale\" string explaining your decision.\n",
                "\n",
                "Example Output JSON:\n",
                "{\n",
                "  \"annotations\": [\"O\", \"B-GEN\", \"I-GEN\", \"O\"],\n",
                "  \"rationale\": \"Explanation here...\"\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "GEN_examples = {\n",
                "    \"input_str\": [\n",
                "        \"Women are all such bad drivers\",\n",
                "        \"Everyone from the city is rude and unfriendly\",\n",
                "        \"John is usually late to meetings\",\n",
                "        \"The college students on my street are always so loud\"\n",
                "    ],\n",
                "    \"rationale\": [\n",
                "        \"The use of the word 'women' in this broad statement is a generalization because it is not about any specific woman or group of women. The use of the words 'are' and 'all' is a ubiquitous classification, extending the generalization entity another two words.\",\n",
                "        \"The phrase 'Everyone from the city' generalizes the behavior of all people from the city, which is a broad and unjustified assumption. The words 'is' and 'rude and unfriendly' extend this generalization.\",\n",
                "        \"This phrase makes a statement about John's punctuality, but does it is specific to one person, and uses the word 'usually' which is a hedge and not a generalization.\",\n",
                "        \"This phrase unfairly characterizes a large group of people (country people) as loud. The use of the word 'always' is a ubiquitious classifier, therefore this contains a generalization.\"\n",
                "    ],\n",
                "    \"annotations\": [\n",
                "        [\"B-GEN\", \"I-GEN\", \"I-GEN\", \"O\", \"O\", \"O\"],\n",
                "        [\"B-GEN\", \"I-GEN\", \"I-GEN\", \"I-GEN\", \"O\", \"O\", \"O\"],\n",
                "        [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"],\n",
                "        [\"O\", \"B-GEN\", \"I-GEN\", \"I-GEN\", \"I-GEN\", \"I-GEN\", \"I-GEN\", \"O\", \"O\"]\n",
                "    ]\n",
                "}\n",
                "\n",
                "# Constructing Few-Shot Examples for the Prompt\n",
                "FEW_SHOT_PROMPT = \"\"\n",
                "for i, inp in enumerate(GEN_examples[\"input_str\"]):\n",
                "    FEW_SHOT_PROMPT += f\"Input: {inp}\\n\"\n",
                "    FEW_SHOT_PROMPT += f\"Rationale: {GEN_examples['rationale'][i]}\\n\"\n",
                "    FEW_SHOT_PROMPT += f\"Annotations: {GEN_examples['annotations'][i]}\\n\\n\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- LOAD DATASET (Hugging Face) ---\n",
                "print(\"Loading HF dataset...\")\n",
                "dataset = load_dataset(\"ethical-spectacle/gus-dataset-v1\", split=\"train\") # Adjust split if needed\n",
                "print(f\"Loaded {len(dataset)} examples.\")\n",
                "\n",
                "# Extract text_str\n",
                "texts_hf = dataset[\"text_str\"]\n",
                "# limitting to 5 for testing\n",
                "test_texts = texts_hf[:5]\n",
                "print(f\"Sample text: {test_texts[0]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANNOTATION FUNCTION ---\n",
                "\n",
                "def annotate_text(text):\n",
                "    prompt = f\"\"\"{SYSTEM_INSTRUCTION}\n",
                "\n",
                "Here are some examples:\n",
                "{FEW_SHOT_PROMPT}\n",
                "\n",
                "Now annotate this input:\n",
                "Input: {text}\n",
                "Provide the Output JSON:\n",
                "\"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = model.generate_content(prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
                "        return json.loads(response.text)\n",
                "    except Exception as e:\n",
                "        print(f\"Error annotating text: {text[:50]}... | Error: {e}\")\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- RUN ANNOTATION LOOP (Hugging Face Dataset) ---\n",
                "\n",
                "output_file_hf = \"gemini_annotations.json\"\n",
                "\n",
                "# 1. Load existing annotations if available\n",
                "if os.path.exists(output_file_hf):\n",
                "    with open(output_file_hf, 'r') as f:\n",
                "        try:\n",
                "            annotated_results_hf = json.load(f)\n",
                "            print(f\"Loaded {len(annotated_results_hf)} existing annotations.\")\n",
                "        except json.JSONDecodeError:\n",
                "            print(\"Could not decode existing JSON. Starting from scratch (backing up old file).\")\n",
                "            os.rename(output_file_hf, f\"{output_file_hf}.bak\")\n",
                "            annotated_results_hf = []\n",
                "else:\n",
                "    annotated_results_hf = []\n",
                "\n",
                "# 2. Determine start index\n",
                "start_index = len(annotated_results_hf)\n",
                "print(f\"Resuming annotation from index {start_index} in HF dataset...\")\n",
                "\n",
                "# 3. Processing Loop\n",
                "# Iterate through the remaining texts\n",
                "for i, text in enumerate(tqdm(texts_hf[start_index:], desc=\"Annotating HF\", initial=start_index, total=len(texts_hf))):\n",
                "    \n",
                "    # Retry logic for robustness\n",
                "    max_retries = 3\n",
                "    result = None\n",
                "    for attempt in range(max_retries):\n",
                "        result = annotate_text(text)\n",
                "        if result:\n",
                "            break\n",
                "        print(f\"Retry {attempt+1}/{max_retries}...\")\n",
                "        time.sleep(2) # Wait a bit longer on retry\n",
                "\n",
                "    # Append result (success or failure)\n",
                "    if result:\n",
                "        annotated_results_hf.append({\n",
                "            \"text\": text,\n",
                "            \"gemini_annotations\": result.get(\"annotations\", []),\n",
                "            \"gemini_rationale\": result.get(\"rationale\", \"\")\n",
                "        })\n",
                "    else:\n",
                "        annotated_results_hf.append({\n",
                "            \"text\": text,\n",
                "            \"gemini_annotations\": [],\n",
                "            \"gemini_rationale\": \"ERROR_FAILED_AFTER_RETRIES\"\n",
                "        })\n",
                "\n",
                "    # 4. Incremental Save (Every 10 items)\n",
                "    if (len(annotated_results_hf)) % 10 == 0:\n",
                "        with open(output_file_hf, 'w') as f:\n",
                "            json.dump(annotated_results_hf, f, indent=2)\n",
                "\n",
                "    # Rate limit sleep\n",
                "    time.sleep(1.0) \n",
                "\n",
                "# Final Save\n",
                "with open(output_file_hf, 'w') as f:\n",
                "    json.dump(annotated_results_hf, f, indent=2)\n",
                "\n",
                "print(f\"Completed HF! Total annotations: {len(annotated_results_hf)} saved to {output_file_hf}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Local No-Bias Dataset Annotation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- LOAD LOCAL DATASET ---\n",
                "import json\n",
                "\n",
                "print(\"Loading Local dataset from '../dataset/bias_sentences.json'...\")\n",
                "try:\n",
                "    with open(\"../dataset/bias_sentences.json\", \"r\") as f:\n",
                "        data_local = json.load(f)\n",
                "\n",
                "    # Filter for no bias\n",
                "    entries_no_bias = [entry for entry in data_local[\"entries\"] if not entry.get(\"has_bias\", True)]\n",
                "    texts_local = [entry[\"text\"] for entry in entries_no_bias]\n",
                "\n",
                "    print(f\"Loaded {len(texts_local)} examples without bias.\")\n",
                "    if texts_local:\n",
                "        print(f\"Sample text: {texts_local[0]}\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Error: '../dataset/bias_sentences.json' not found. Please ensure the file exists.\")\n",
                "    texts_local = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- RUN ANNOTATION LOOP (Local No-Bias Dataset) ---\n",
                "\n",
                "output_file_local = \"no_bias_annotations.json\"\n",
                "\n",
                "# 1. Load existing annotations if available\n",
                "if os.path.exists(output_file_local):\n",
                "    with open(output_file_local, 'r') as f:\n",
                "        try:\n",
                "            annotated_results_local = json.load(f)\n",
                "            print(f\"Loaded {len(annotated_results_local)} existing annotations.\")\n",
                "        except json.JSONDecodeError:\n",
                "            print(\"Could not decode existing JSON. Starting from scratch.\")\n",
                "            os.rename(output_file_local, f\"{output_file_local}.bak\")\n",
                "            annotated_results_local = []\n",
                "else:\n",
                "    annotated_results_local = []\n",
                "\n",
                "# 2. Determine start index\n",
                "start_index_local = len(annotated_results_local)\n",
                "print(f\"Resuming annotation from index {start_index_local} in Local dataset...\")\n",
                "\n",
                "# 3. Processing Loop\n",
                "if texts_local:\n",
                "    for i, text in enumerate(tqdm(texts_local[start_index_local:], desc=\"Annotating Local\", initial=start_index_local, total=len(texts_local))):\n",
                "        \n",
                "        max_retries = 3\n",
                "        result = None\n",
                "        for attempt in range(max_retries):\n",
                "            result = annotate_text(text)\n",
                "            if result:\n",
                "                break\n",
                "            print(f\"Retry {attempt+1}/{max_retries}...\")\n",
                "            time.sleep(2)\n",
                "\n",
                "        if result:\n",
                "            annotated_results_local.append({\n",
                "                \"text\": text,\n",
                "                \"gemini_annotations\": result.get(\"annotations\", []),\n",
                "                \"gemini_rationale\": result.get(\"rationale\", \"\")\n",
                "            })\n",
                "        else:\n",
                "            annotated_results_local.append({\n",
                "                \"text\": text,\n",
                "                \"gemini_annotations\": [],\n",
                "                \"gemini_rationale\": \"ERROR_FAILED_AFTER_RETRIES\"\n",
                "            })\n",
                "\n",
                "        if (len(annotated_results_local)) % 10 == 0:\n",
                "            with open(output_file_local, 'w') as f:\n",
                "                json.dump(annotated_results_local, f, indent=2)\n",
                "\n",
                "        time.sleep(1.0)\n",
                "\n",
                "    with open(output_file_local, 'w') as f:\n",
                "        json.dump(annotated_results_local, f, indent=2)\n",
                "\n",
                "    print(f\"Completed Local! Total annotations: {len(annotated_results_local)} saved to {output_file_local}\")\n",
                "else:\n",
                "    print(\"Skipping local annotation loop due to missing data.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "inspectus-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}