# llm-attention-explained
This repository hosts the code, experiments, and prototype developed for my Masterâ€™s thesis: Interpretable Large Language Models through Attention Mechanism Visualization. It provides tools for exploring attention patterns, assessing bias, and validating interpretability in LLMs.
